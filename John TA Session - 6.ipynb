{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will be using data from two tables from different Wikipedia articles. In the commented out cell below I use pandas to read in the two tables by scraping them. I then copy and paste the dictionary into the script so you don't have to scrape Wikipedia every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df=pd.read_html('https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_income', header=0)\n",
    "state_inc=df[1].copy()\n",
    "state_inc_dict=state_inc.to_dict()\n",
    "print(state_inc_dict)\n",
    "\n",
    "df=pd.read_html('https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_area', header=1)\n",
    "state_area=df[0].copy()\n",
    "state_area_dict = state_area.to_dict()\n",
    "print(state_area_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dictionary contains income data for all U.S. states and territores from 2014 to 2018. The second has the areas of all states and territories. (p.s. don't let your horizontal lines be this long!)\n",
    "\n",
    "As you can see, this data looks pleasing to the eyes, but won't work well in pandas. Note the $, commas, and hyphens turn the numbers into strings. Let's clean the data up a little using what we learned last week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cite: https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_income\n",
    "state_inc_dict = {'Rank': {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '10', 10: '11', 11: '12', 12: '13', 13: '14', 14: '15', 15: '16', 16: '17', 17: '18', 18: '19', 19: '20', 20: '—', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56'}, 'State or territory': {0: 'Washington, D.C.', 1: 'Maryland', 2: 'New Jersey', 3: 'Hawaii', 4: 'Massachusetts', 5: 'Connecticut', 6: 'California', 7: 'New Hampshire', 8: 'Alaska', 9: 'Washington', 10: 'Virginia', 11: 'Colorado', 12: 'Utah', 13: 'Minnesota', 14: 'New York', 15: 'Illinois', 16: 'Delaware', 17: 'Rhode Island', 18: 'North Dakota', 19: 'Oregon', 20: 'United States', 21: 'Wyoming', 22: 'Pennsylvania', 23: 'Vermont', 24: 'Wisconsin', 25: 'Texas', 26: 'Iowa', 27: 'Nebraska', 28: 'Arizona', 29: 'Georgia', 30: 'Nevada', 31: 'Kansas', 32: 'Michigan', 33: 'South Dakota', 34: 'Ohio', 35: 'Indiana', 36: 'Maine', 37: 'Idaho', 38: 'Florida', 39: 'Montana', 40: 'Missouri', 41: 'North Carolina', 42: 'Tennessee', 43: 'South Carolina', 44: 'Oklahoma', 45: 'Kentucky', 46: 'Alabama', 47: 'Guam', 48: 'Louisiana', 49: 'New Mexico', 50: 'Arkansas', 51: 'Mississippi', 52: 'West Virginia', 53: 'Virgin Islands (U.S.)', 54: 'American Samoa', 55: 'Northern Mariana Islands', 56: 'Puerto Rico'}, '2018': {0: '$85,203', 1: '$83,242', 2: '$81,740', 3: '$80,212', 4: '$79,835', 5: '$76,348', 6: '$75,277', 7: '$74,991', 8: '$74,346', 9: '$74,073', 10: '$72,577', 11: '$71,953', 12: '$71,414', 13: '$70,315', 14: '$67,844', 15: '$65,030', 16: '$64,805', 17: '$64,340', 18: '$63,837', 19: '$63,426', 20: '$63,179', 21: '$61,584', 22: '$60,905', 23: '$60,782', 24: '$60,773', 25: '$60,629', 26: '$59,955', 27: '$59,566', 28: '$59,246', 29: '$58,756', 30: '$58,646', 31: '$58,218', 32: '$56,697', 33: '$56,274', 34: '$56,111', 35: '$55,746', 36: '$55,602', 37: '$55,583', 38: '$55,462', 39: '$55,328', 40: '$54,478', 41: '$53,855', 42: '$52,375', 43: '$52,306', 44: '$51,924', 45: '$50,247', 46: '$49,861', 47: '—', 48: '$47,905', 49: '$47,169', 50: '$47,062', 51: '$44,717', 52: '$44,097', 53: '—', 54: '—', 55: '—', 56: '$20,296'}, '2017': {0: '$82,372', 1: '$80,776', 2: '$80,088', 3: '$77,765', 4: '$77,385', 5: '$74,168', 6: '$71,805', 7: '$73,381', 8: '$73,181', 9: '$70,979', 10: '$71,535', 11: '$69,117', 12: '$65,358', 13: '$68,388', 14: '$64,894', 15: '$62,992', 16: '$62,852', 17: '$63,870', 18: '$61,843', 19: '$60,212', 20: '$60,336', 21: '$60,434', 22: '$59,105', 23: '$57,513', 24: '$59,305', 25: '$59,206', 26: '$58,570', 27: '$59,970', 28: '$56,581', 29: '$56,183', 30: '$58,003', 31: '$56,422', 32: '$54,909', 33: '$56,521', 34: '$54,021', 35: '$54,181', 36: '$55,277', 37: '$52,225', 38: '$52,594', 39: '$53,386', 40: '$53,578', 41: '$52,752', 42: '$51,340', 43: '$50,570', 44: '$50,051', 45: '$48,375', 46: '$48,123', 47: '—', 48: '$46,145', 49: '$46,744', 50: '$45,869', 51: '$43,529', 52: '$43,469', 53: '—', 54: '—', 55: '—', 56: '$19,343'}, '2016': {0: '$75,506', 1: '$78,945', 2: '$76,126', 3: '$74,511', 4: '$75,297', 5: '$73,433', 6: '$67,739', 7: '$70,936', 8: '$76,440', 9: '$67,106', 10: '$68,114', 11: '$65,685', 12: '$65,977', 13: '$65,599', 14: '$62,909', 15: '$60,960', 16: '$61,757', 17: '$60,596', 18: '$60,656', 19: '$57,532', 20: '$57,617', 21: '$59,882', 22: '$56,907', 23: '$57,677', 24: '$56,811', 25: '$56,565', 26: '$56,247', 27: '$56,927', 28: '$53,558', 29: '$53,559', 30: '$55,180', 31: '$54,935', 32: '$52,491', 33: '$54,467', 34: '$52,344', 35: '$52,314', 36: '$53,079', 37: '$51,807', 38: '$50,860', 39: '$50,027', 40: '$51,746', 41: '$50,584', 42: '$48,547', 43: '$49,501', 44: '$49,176', 45: '$46,659', 46: '$46,257', 47: '—', 48: '$45,146', 49: '$46,748', 50: '$44,334', 51: '$41,754', 52: '$43,385', 53: '—', 54: '—', 55: '—', 56: '$20,078'}, '2015': {0: '$75,628', 1: '$75,847', 2: '$72,222', 3: '$73,486', 4: '$70,628', 5: '$71,346', 6: '$64,500', 7: '$70,303', 8: '$73,355', 9: '$64,129', 10: '$66,262', 11: '$63,909', 12: '$62,912', 13: '$63,488', 14: '$60,850', 15: '$59,588', 16: '$61,255', 17: '$58,073', 18: '$60,557', 19: '$54,148', 20: '$55,775', 21: '$60,214', 22: '$55,702', 23: '$56,990', 24: '$55,638', 25: '$55,653', 26: '$54,736', 27: '$54,996', 28: '$51,492', 29: '$51,244', 30: '$52,431', 31: '$53,906', 32: '$51,084', 33: '$53,017', 34: '$51,075', 35: '$50,532', 36: '$51,494', 37: '$48,275', 38: '$49,426', 39: '$49,509', 40: '$50,238', 41: '$47,830', 42: '$47,275', 43: '$47,238', 44: '$48,568', 45: '$45,215', 46: '$44,765', 47: '—', 48: '$45,727', 49: '$45,382', 50: '$41,995', 51: '$40,593', 52: '$42,019', 53: '—', 54: '—', 55: '—', 56: '$18,626'}, '2014[note 2]': {0: '$71,648', 1: '$73,971', 2: '$71,919', 3: '$69,592', 4: '$69,160', 5: '$70,048', 6: '$61,933', 7: '$66,532', 8: '$71,583', 9: '$61,366', 10: '$64,902', 11: '$61,303', 12: '$60,922', 13: '$61,481', 14: '$58,878', 15: '$57,444', 16: '$59,716', 17: '$54,891', 18: '$59,029', 19: '$51,075', 20: '$53,657', 21: '$57,055', 22: '$53,234', 23: '$54,166', 24: '$52,622', 25: '$53,035', 26: '$53,712', 27: '$52,686', 28: '$50,068', 29: '$49,321', 30: '$51,450', 31: '$52,504', 32: '$49,847', 33: '$50,979', 34: '$49,308', 35: '$49,446', 36: '$49,462', 37: '$47,861', 38: '$47,463', 39: '$46,328', 40: '$48,363', 41: '$46,556', 42: '$44,361', 43: '$45,238', 44: '$47,529', 45: '$42,958', 46: '$42,830', 47: '$48,274[3]', 48: '$44,555', 49: '$44,803', 50: '$41,262', 51: '$39,680', 52: '$41,059', 53: '$37,254[4]', 54: '$23,892[5]', 55: '$19,958[6]', 56: '$18,928'}}\n",
    "inc_df = pd.DataFrame(state_inc_dict)\n",
    "inc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cite: https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_area\n",
    "nan='NaN'\n",
    "state_area_dict={'State': {0: 'Alaska', 1: 'Texas', 2: 'California', 3: 'Montana', 4: 'New Mexico', 5: 'Arizona', 6: 'Nevada', 7: 'Colorado', 8: 'Oregon', 9: 'Wyoming', 10: 'Michigan', 11: 'Minnesota', 12: 'Utah', 13: 'Idaho', 14: 'Kansas', 15: 'Nebraska', 16: 'South Dakota', 17: 'Washington', 18: 'North Dakota', 19: 'Oklahoma', 20: 'Missouri', 21: 'Florida', 22: 'Wisconsin', 23: 'Georgia', 24: 'Illinois', 25: 'Iowa', 26: 'New York', 27: 'North Carolina', 28: 'Arkansas', 29: 'Alabama', 30: 'Louisiana', 31: 'Mississippi', 32: 'Pennsylvania', 33: 'Ohio', 34: 'Virginia', 35: 'Tennessee', 36: 'Kentucky', 37: 'Indiana', 38: 'Maine', 39: 'South Carolina', 40: 'West Virginia', 41: 'Maryland', 42: 'Hawaii', 43: 'Massachusetts', 44: 'Vermont', 45: 'New Hampshire', 46: 'New Jersey', 47: 'Connecticut', 48: 'Delaware', 49: 'Rhode Island', 50: 'District of Columbia', 51: 'Puerto Rico', 52: 'Northern Mariana Islands', 53: 'United States Virgin Islands', 54: 'American Samoa', 55: 'Guam', 56: 'Minor Outlying Islands[3][a]', 57: 'Contiguous United States', 58: '50 states and District of Columbia', 59: 'All 50 states, District of Columbia, and U.S. territories'}, 'Rank': {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '10', 10: '11', 11: '12', 12: '13', 13: '14', 14: '15', 15: '16', 16: '17', 17: '18', 18: '19', 19: '20', 20: '21', 21: '22', 22: '23', 23: '24', 24: '25', 25: '26', 26: '27', 27: '28', 28: '29', 29: '30', 30: '31', 31: '32', 32: '33', 33: '34', 34: '35', 35: '36', 36: '37', 37: '38', 38: '39', 39: '40', 40: '41', 41: '42', 42: '43', 43: '44', 44: '45', 45: '46', 46: '47', 47: '48', 48: '49', 49: '50', 50: '—', 51: '—', 52: '—', 53: '—', 54: '—', 55: '—', 56: '—', 57: 'Total', 58: 'Total', 59: 'Total'}, 'sq mi': {0: 665384.04, 1: 268596.46, 2: 163694.74, 3: 147039.71, 4: 121590.3, 5: 113990.3, 6: 110571.82, 7: 104093.67, 8: 98378.54, 9: 97813.01, 10: 96713.51, 11: 86935.83, 12: 84896.88, 13: 83568.95, 14: 82278.36, 15: 77347.81, 16: 77115.68, 17: 71297.95, 18: 70698.32, 19: 69898.87, 20: 69706.99, 21: 65757.7, 22: 65496.38, 23: 59425.15, 24: 57913.55, 25: 56272.81, 26: 54554.98, 27: 53819.16, 28: 53178.55, 29: 52420.07, 30: 52378.13, 31: 48431.78, 32: 46054.34, 33: 44825.58, 34: 42774.93, 35: 42144.25, 36: 40407.8, 37: 36419.55, 38: 35379.74, 39: 32020.49, 40: 24230.04, 41: 12405.93, 42: 10931.72, 43: 10554.39, 44: 9616.36, 45: 9349.16, 46: 8722.58, 47: 5543.41, 48: 2488.72, 49: 1544.89, 50: 68.34, 51: 5324.84, 52: 1975.57, 53: 732.93, 54: 581.05, 55: 570.62, 56: 16.0, 57: 3120426.47, 58: 3796742.23, 59: 3805943.26}, 'km2': {0: 1723337, 1: 695662, 2: 423967, 3: 380831, 4: 314917, 5: 295234, 6: 286380, 7: 269601, 8: 254799, 9: 253335, 10: 250487, 11: 225163, 12: 219882, 13: 216443, 14: 213100, 15: 200330, 16: 199729, 17: 184661, 18: 183108, 19: 181037, 20: 180540, 21: 170312, 22: 169635, 23: 153910, 24: 149995, 25: 145746, 26: 141297, 27: 139391, 28: 137732, 29: 135767, 30: 135659, 31: 125438, 32: 119280, 33: 116098, 34: 110787, 35: 109153, 36: 104656, 37: 94326, 38: 91633, 39: 82933, 40: 62756, 41: 32131, 42: 28313, 43: 27336, 44: 24906, 45: 24214, 46: 22591, 47: 14357, 48: 6446, 49: 4001, 50: 177, 51: 13791, 52: 5117, 53: 1898, 54: 1505, 55: 1478, 56: 41, 57: 8081867, 58: 9833517, 59: 9857348}, 'Rank.1': {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '10', 9: '9', 10: '22', 11: '14', 12: '12', 13: '11', 14: '13', 15: '15', 16: '16', 17: '20', 18: '17', 19: '19', 20: '18', 21: '26', 22: '25', 23: '21', 24: '24', 25: '23', 26: '30', 27: '29', 28: '27', 29: '28', 30: '33', 31: '31', 32: '32', 33: '35', 34: '36', 35: '34', 36: '37', 37: '38', 38: '39', 39: '40', 40: '41', 41: '42', 42: '47', 43: '45', 44: '43', 45: '44', 46: '46', 47: '48', 48: '49', 49: '50', 50: '—', 51: '—', 52: '—', 53: '—', 54: '—', 55: '—', 56: '—', 57: nan, 58: '—', 59: nan}, 'sq mi.1': {0: 570640.95, 1: 261231.71, 2: 155779.22, 3: 145545.8, 4: 121298.15, 5: 113594.08, 6: 109781.18, 7: 103641.89, 8: 95988.01, 9: 97093.14, 10: 56538.9, 11: 79626.74, 12: 82169.62, 13: 82643.12, 14: 81758.72, 15: 76824.17, 16: 75811.0, 17: 66455.52, 18: 69000.8, 19: 68594.92, 20: 68741.52, 21: 53624.76, 22: 54157.8, 23: 57513.49, 24: 55518.93, 25: 55857.13, 26: 47126.4, 27: 48617.91, 28: 52035.48, 29: 50645.33, 30: 43203.9, 31: 46923.27, 32: 44742.7, 33: 40860.69, 34: 39490.09, 35: 41234.9, 36: 39486.34, 37: 35826.11, 38: 30842.92, 39: 30060.7, 40: 24038.21, 41: 9707.24, 42: 6422.63, 43: 7800.06, 44: 9216.66, 45: 8952.65, 46: 7354.22, 47: 4842.36, 48: 1948.54, 49: 1033.81, 50: 61.05, 51: 3423.78, 52: 182.33, 53: 134.32, 54: 76.46, 55: 209.8, 56: 16.0, 57: 2954841.42, 58: 3531905.43, 59: 3535948.12}, 'km2.1': {0: 1477953, 1: 676587, 2: 403466, 3: 376962, 4: 314161, 5: 294207, 6: 284332, 7: 268431, 8: 248608, 9: 251470, 10: 146435, 11: 206232, 12: 212818, 13: 214045, 14: 211754, 15: 198974, 16: 196350, 17: 172119, 18: 178711, 19: 177660, 20: 178040, 21: 138887, 22: 140268, 23: 148959, 24: 143793, 25: 144669, 26: 122057, 27: 125920, 28: 134771, 29: 131171, 30: 111898, 31: 121531, 32: 115883, 33: 105829, 34: 102279, 35: 106798, 36: 102269, 37: 92789, 38: 79883, 39: 77857, 40: 62259, 41: 25142, 42: 16635, 43: 20202, 44: 23871, 45: 23187, 46: 19047, 47: 12542, 48: 5047, 49: 2678, 50: 158, 51: 8868, 52: 472, 53: 348, 54: 198, 55: 543, 56: 41, 57: 7653004, 58: 9147593, 59: 9158064}, '% land': {0: nan, 1: nan, 2: nan, 3: nan, 4: nan, 5: nan, 6: nan, 7: nan, 8: nan, 9: nan, 10: nan, 11: nan, 12: nan, 13: nan, 14: nan, 15: nan, 16: nan, 17: nan, 18: nan, 19: nan, 20: nan, 21: nan, 22: nan, 23: nan, 24: nan, 25: nan, 26: nan, 27: nan, 28: nan, 29: nan, 30: nan, 31: nan, 32: nan, 33: nan, 34: nan, 35: nan, 36: nan, 37: nan, 38: nan, 39: nan, 40: nan, 41: nan, 42: nan, 43: nan, 44: nan, 45: nan, 46: nan, 47: nan, 48: nan, 49: nan, 50: nan, 51: nan, 52: nan, 53: nan, 54: nan, 55: nan, 56: '—', 57: nan, 58: nan, 59: nan}, 'Rank.2': {0: '1', 1: '8', 2: '6', 3: '26', 4: '49', 5: '48', 6: '36', 7: '44', 8: '20', 9: '37', 10: '2', 11: '9', 12: '17', 13: '33', 14: '42', 15: '41', 16: '29', 17: '11', 18: '24', 19: '30', 20: '32', 21: '3', 22: '4', 23: '22', 24: '19', 25: '45', 26: '7', 27: '10', 28: '31', 29: '23', 30: '5', 31: '25', 32: '28', 33: '14', 34: '15', 35: '35', 36: '34', 37: '39', 38: '12', 39: '21', 40: '50', 41: '18', 42: '13', 43: '16', 44: '46', 45: '47', 46: '27', 47: '38', 48: '40', 49: '43', 50: '—', 51: '—', 52: '—', 53: nan, 54: nan, 55: nan, 56: '—', 57: '—', 58: '—', 59: '—'}, 'sq mi.2': {0: '94743.10', 1: '7364.75', 2: '7915.52', 3: '1493.91', 4: '292.15', 5: '396.22', 6: '790.65', 7: '451.78', 8: '2390.53', 9: '719.87', 10: '40174.61', 11: '7309.09', 12: '2727.26', 13: '925.83', 14: '519.64', 15: '523.64', 16: '1304.68', 17: '4842.43', 18: '1697.52', 19: '1303.95', 20: '965.47', 21: '12132.94', 22: '11338.57', 23: '1911.66', 24: '2394.62', 25: '415.68', 26: '7428.58', 27: '5201.25', 28: '1143.07', 29: '1774.74', 30: '9174.23', 31: '1508.51', 32: '1311.64', 33: '3964.89', 34: '3284.84', 35: '909.36', 36: '921.46', 37: '593.44', 38: '4536.82', 39: '1959.79', 40: '191.83', 41: '2698.69', 42: '4509.09', 43: '2754.33', 44: '399.71', 45: '396.51', 46: '1368.36', 47: '701.06', 48: '540.18', 49: '511.07', 50: '7.29', 51: '1901.07', 52: '1793.24', 53: '598.61', 54: '504.60', 55: '360.82', 56: '—', 57: '165584.6', 58: '264836.79', 59: '269995.13'}, 'km2.2': {0: '245384', 1: '19075', 2: '20501', 3: '3869', 4: '757', 5: '1026', 6: '2048', 7: '1170', 8: '6191', 9: '1864', 10: '104052', 11: '18930', 12: '7064', 13: '2398', 14: '1346', 15: '1356', 16: '3379', 17: '12542', 18: '4397', 19: '3377', 20: '2501', 21: '31424', 22: '29367', 23: '4951', 24: '6202', 25: '1077', 26: '19240', 27: '13471', 28: '2961', 29: '4597', 30: '23761', 31: '3907', 32: '3397', 33: '10269', 34: '8508', 35: '2355', 36: '2387', 37: '1537', 38: '11750', 39: '5076', 40: '497', 41: '6990', 42: '11678', 43: '7134', 44: '1035', 45: '1027', 46: '3544', 47: '1816', 48: '1399', 49: '1324', 50: '19', 51: '4924', 52: '4644', 53: '1550', 54: '1307', 55: '935', 56: '—', 57: '428862', 58: '685924', 59: '699284'}, '% water': {0: nan, 1: nan, 2: nan, 3: nan, 4: nan, 5: nan, 6: nan, 7: nan, 8: nan, 9: nan, 10: nan, 11: nan, 12: nan, 13: nan, 14: nan, 15: nan, 16: nan, 17: nan, 18: nan, 19: nan, 20: nan, 21: nan, 22: nan, 23: nan, 24: nan, 25: nan, 26: nan, 27: nan, 28: nan, 29: nan, 30: nan, 31: nan, 32: nan, 33: nan, 34: nan, 35: nan, 36: nan, 37: nan, 38: nan, 39: nan, 40: nan, 41: nan, 42: nan, 43: nan, 44: nan, 45: nan, 46: nan, 47: nan, 48: nan, 49: nan, 50: nan, 51: nan, 52: nan, 53: nan, 54: nan, 55: nan, 56: '—', 57: nan, 58: nan, 59: nan}}\n",
    "area_df = pd.DataFrame(state_area_dict)\n",
    "area_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% land and % water shouldn't be new columns, they were subheadings in the original article. Let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_df=area_df.drop(['% land','% water'], axis=1)\n",
    "area_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On second thought, let's only keep the state name, and the info about total area. While we're at it, let's drop the observations 52 and above. Here we'll use .iloc, because I think it's the least intuitive way to slice a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_df = area_df.iloc[:51,0:3]\n",
    "area_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to the income dataframe! It looks like the footnote got added to the column 2014, let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_df=inc_df.rename({'2014[note 2]': '2014'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take out all strings from the columns that should be numeric. Don't forget to cite your sources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/14596884/remove-text-between-and\n",
    "for year in inc_df.columns[2:]:\n",
    "    inc_df[year]=inc_df[year].apply(lambda x: re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x).replace\\\n",
    "                                    ('$','').replace(',','').replace('—','0'))\n",
    "inc_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mergeing the Data\n",
    "\n",
    "on = column name\n",
    "\n",
    "left_on = column name of base data frame\n",
    "\n",
    "right_on = column name of merging data frame\n",
    "\n",
    "left_index = True if you are using the index of the base dataframe to merge\n",
    "\n",
    "right_index = True if you are using the index of the merging dataframe to merge\n",
    "\n",
    "how=\n",
    "    \n",
    "    -left = keep all data from base dataframe, keep data from merging dataframe only if it merges\n",
    "    -right = keep all data from merging dataframe, keep data from base dataframe only if it merges\n",
    "    -inner = keep only merging data\n",
    "    -outer = keep all data\n",
    "    \n",
    "indicator = True if you want to create a variable _ merge that says where the observation came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge area_df to inc_df keeping all income data, but deleting area data that doesn't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_df = inc_df.merge(area_df, left_on='State or territory', right_on='State', how='left', indicator=True)\n",
    "merger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! Looks like Washington, D.C. did't merge. Turns out the tables used a different naming convention. Let's fix that.\n",
    "\n",
    "Also, note the new names for Rank. Because Rank is in both dfs and we didn't merge on it, pandas renamed them so both will remain in the merged df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_df['State or territory']=inc_df['State or territory'].replace('Washington, D.C.', 'District of Columbia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge = inc_df.merge(area_df, left_on='State or territory', right_on='State', how='left', indicator=True)\n",
    "new_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also merge on multiple columns. For fun, let's see if any of the States have the same rank when it comes to income and total area. To only keep data that merged we specify how='inner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_same_position=inc_df.merge(area_df, left_on=['State or territory', 'Rank'], \n",
    "                                 right_on=['State', 'Rank'], how='inner')\n",
    "merge_same_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 4 matches! These are very special states, so lets use concat to double them up.\n",
    "\n",
    "Concat is very easy, just put the two (or more) dataframes you want to concatenate into a list and there you have it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_merge=pd.concat([merge_same_position,merge_same_position])\n",
    "double_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way this is what the results of a concat look like when the dataframes don't share the same columns. NaN's are filled into the columns that are not shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([merge_same_position, area_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the special states, it looks like the incomes are not integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_merge.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create a new column that contains the summation of income over all available years. Let's do that with our old friend apply! And while we're at it, let's use .loc to only keep this new variable and the state names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_merge['total'] = double_merge.apply(lambda x: sum(int(yr) for yr in x[3:7]), axis=1)\n",
    "total_inc = double_merge.loc[:,['State or territory', 'total']]\n",
    "total_inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge this new column into inc_df, but only keeping inc_df data and double data that matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_total = inc_df.merge(total_inc, on='State or territory', how='left', indicator=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... It looks like extra data was added. Let's investigate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(with_total) == len(inc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like both sets of double were merged! That's because pd.merge does a many to many merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_total[with_total['_merge']=='both']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Data\n",
    "\n",
    "First, let's turn the income data into long data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method we'll go over uses a stub. While we could use 20 as the stub, I think it makes more sense to just add a stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_stub_df = inc_df.copy()\n",
    "for year in inc_stub_df.columns[2:]:\n",
    "    inc_stub_df = inc_stub_df.rename({year: f'income{year}'},axis=1)\n",
    "inc_stub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wide_to_long, as the name suggests, will turn a dataset wide data set into a long data set.\n",
    "\n",
    "stubnames = the name of the stub, these will become new columns\n",
    "\n",
    "i = the column that contains the identifying info, this column will turn into an index\n",
    "\n",
    "j = the new name for what were the column names, this will also become an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_inc=pd.wide_to_long(inc_stub_df, stubnames='income', i='State or territory', j='year')\n",
    "long_inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the indexes back in the df as columns, we can do so with .reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_inc.reset_index(inplace=True)\n",
    "long_inc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melt is the other method to reshape wide to long, which does not require stubnames.\n",
    "\n",
    "id_vars = the columns that should stay the same\n",
    "\n",
    "value_vars = columns that you want to reshape\n",
    "\n",
    "var_name = the name of what were the columns\n",
    "\n",
    "value_name = the name of what were the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_df.melt(id_vars=['State or territory','Rank'], value_vars=inc_df.columns[2:], \n",
    "            var_name='year', value_name='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_inc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_wide = long_inc.pivot(index=['State or territory', 'Rank'], columns='year', values='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_wide.reset_index(inplace=True)\n",
    "inc_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_wide.sort_values('Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
